{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simranarora1996/US-income-data-sampling/blob/main/Monte_Carlo_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Missing Data Imputation (Adult Census 1994) — MICE vs MH vs Gibbs\n",
        "\n",
        "**Research question:** How do different imputation methods affect income classification when key continuous predictors contain missing values?\n",
        "\n",
        "**Methods compared**\n",
        "- Frequentist baseline: Mean imputation\n",
        "- MICE (Iterative imputation)\n",
        "- Metropolis–Hastings (from scratch)\n",
        "- Gibbs sampling (from scratch)\n",
        "\n",
        "**Evaluation**\n",
        "- Downstream model: Logistic Regression\n",
        "- Predictive metric: AUC (primary), plus Accuracy / F1 / LogLoss\n",
        "- Imputation quality: MAE / RMSE on artificially masked test entries\n",
        "- Missingness levels: 5%, 10%, 20% (MCAR)\n",
        "\n"
      ],
      "metadata": {
        "id": "yNC1qPfcTIT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, log_loss, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "np.random.seed(42)\n",
        "\n"
      ],
      "metadata": {
        "id": "uN8EdaMoTLNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Load data and select predictors\n",
        "\n",
        "We use three continuous predictors (Option A):\n",
        "- `age`\n",
        "- `hours.per.week`\n",
        "- `education.num`\n",
        "\n",
        "Target:\n",
        "- `income` converted to 0/1 (<=50K vs >50K)\n"
      ],
      "metadata": {
        "id": "sxjN9EJmkH3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"adult.csv\"  # adjust if needed\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "display(df.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "bwCkqzsgTSAf",
        "outputId": "98b20a09-cfbe-40f1-8f64-da4060184bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'adult.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2863336632.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"adult.csv\"\u001b[0m  \u001b[0;31m# adjust if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'adult.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"income\"\n",
        "continuous_cols = [\"age\", \"hours.per.week\", \"education.num\"]\n",
        "\n",
        "y_full = df[target_col].astype(str).str.strip().eq(\">50K\").astype(int)\n",
        "X_full = df[continuous_cols].copy()\n",
        "\n",
        "print(\"Target counts (0=<=50K, 1=>50K):\")\n",
        "print(y_full.value_counts())\n",
        "display(X_full.describe().T)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4so-eWSpTYPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Stratified sample (N=1000) and baseline logistic regression\n",
        "\n",
        "We sample N=1000 with class proportions similar to the full dataset.\n"
      ],
      "metadata": {
        "id": "isvxqdLSkQC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_sample(df, y, cols, N=1000, seed=42):\n",
        "    tmp = df.copy()\n",
        "    tmp[\"_y\"] = y.values\n",
        "\n",
        "    p1 = tmp[\"_y\"].mean()\n",
        "    n1 = int(round(N * p1))\n",
        "    n0 = N - n1\n",
        "\n",
        "    df0 = tmp[tmp[\"_y\"] == 0].sample(n=n0, random_state=seed)\n",
        "    df1 = tmp[tmp[\"_y\"] == 1].sample(n=n1, random_state=seed)\n",
        "\n",
        "    out = pd.concat([df0, df1]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "    y_out = out[target_col].astype(str).str.strip().eq(\">50K\").astype(int)\n",
        "    X_out = out[cols].copy()\n",
        "    return X_out, y_out\n",
        "\n",
        "X_s, y_s = stratified_sample(df, y_full, continuous_cols, N=1000, seed=42)\n",
        "\n",
        "print(\"Sample shape:\", X_s.shape)\n",
        "print(\"Sample target distribution:\")\n",
        "print(y_s.value_counts(normalize=True).rename(\"proportion\"))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MDu1K-KETe3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_s, y_s, test_size=0.25, random_state=42, stratify=y_s\n",
        ")\n",
        "\n",
        "baseline_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logreg\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
        "])\n",
        "\n",
        "baseline_model.fit(X_train, y_train)\n",
        "proba = baseline_model.predict_proba(X_test)[:, 1]\n",
        "pred = (proba >= 0.5).astype(int)\n",
        "\n",
        "baseline_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, pred),\n",
        "    \"AUC\": roc_auc_score(y_test, proba),\n",
        "    \"F1\": f1_score(y_test, pred),\n",
        "    \"LogLoss\": log_loss(y_test, proba),\n",
        "}\n",
        "display(pd.DataFrame([baseline_metrics]).T.rename(columns={0: \"Baseline (no missingness)\"}))\n",
        "print(\"Confusion matrix [[TN FP],[FN TP]]:\")\n",
        "print(confusion_matrix(y_test, pred))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ElTp0ZBaTkx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Missingness injection (MCAR)\n",
        "\n",
        "We inject missingness into each predictor independently at:\n",
        "- 5%, 10%, 20%\n",
        "\n",
        "To keep comparisons fair, all methods use the same masks for a given rate.\n"
      ],
      "metadata": {
        "id": "GQWywVgIkWyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rates = [0.05, 0.10, 0.20]\n",
        "\n",
        "def make_mcar_mask(X: pd.DataFrame, missing_rate: float, seed: int) -> pd.DataFrame:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    mask = pd.DataFrame(False, index=X.index, columns=X.columns)\n",
        "\n",
        "    n = len(X)\n",
        "    k = int(round(missing_rate * n))\n",
        "    for col in X.columns:\n",
        "        idx = rng.choice(X.index.to_numpy(), size=k, replace=False)\n",
        "        mask.loc[idx, col] = True\n",
        "    return mask\n",
        "\n",
        "def apply_mask(X: pd.DataFrame, mask: pd.DataFrame) -> pd.DataFrame:\n",
        "    X_m = X.copy()\n",
        "    for col in X.columns:\n",
        "        X_m.loc[mask[col], col] = np.nan\n",
        "    return X_m\n",
        "\n",
        "def missing_report(X_m: pd.DataFrame) -> pd.DataFrame:\n",
        "    return pd.DataFrame({\n",
        "        \"missing_count\": X_m.isna().sum(),\n",
        "        \"missing_pct\": (X_m.isna().mean() * 100).round(2)\n",
        "    })\n",
        "\n",
        "data_by_rate = {}\n",
        "\n",
        "for r in missing_rates:\n",
        "    seed_r = int(r * 10_000) + 42\n",
        "    mask_tr = make_mcar_mask(X_train, r, seed=seed_r)\n",
        "    mask_te = make_mcar_mask(X_test,  r, seed=seed_r + 1)\n",
        "\n",
        "    Xtr_m = apply_mask(X_train, mask_tr)\n",
        "    Xte_m = apply_mask(X_test,  mask_te)\n",
        "\n",
        "    data_by_rate[r] = {\n",
        "        \"X_train_true\": X_train.copy(),\n",
        "        \"X_test_true\": X_test.copy(),\n",
        "        \"y_train\": y_train.copy(),\n",
        "        \"y_test\": y_test.copy(),\n",
        "        \"mask_train\": mask_tr,\n",
        "        \"mask_test\": mask_te,\n",
        "        \"X_train_miss\": Xtr_m,\n",
        "        \"X_test_miss\": Xte_m\n",
        "    }\n",
        "\n",
        "    print(f\"\\nMissing rate = {int(r*100)}%\")\n",
        "    display(missing_report(Xtr_m))\n",
        "\n"
      ],
      "metadata": {
        "id": "Rcliy7V-Tnz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Common evaluation + imputation error functions\n",
        "\n",
        "- Logistic regression is trained on imputed training data and evaluated on imputed test data.\n",
        "- Imputation error is computed only on the artificially masked entries.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fcpaWd4JUZB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_logreg(X_train_imp, y_train, X_test_imp, y_test):\n",
        "    model = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"logreg\", LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
        "    ])\n",
        "    model.fit(X_train_imp, y_train)\n",
        "\n",
        "    proba = model.predict_proba(X_test_imp)[:, 1]\n",
        "    pred = (proba >= 0.5).astype(int)\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy_score(y_test, pred),\n",
        "        \"AUC\": roc_auc_score(y_test, proba),\n",
        "        \"F1\": f1_score(y_test, pred),\n",
        "        \"LogLoss\": log_loss(y_test, proba),\n",
        "    }\n",
        "\n",
        "def imputation_error(true_df, imp_df, mask_df):\n",
        "    rows = []\n",
        "    for col in true_df.columns:\n",
        "        true_vals = true_df.loc[mask_df[col], col].to_numpy()\n",
        "        imp_vals  = imp_df.loc[mask_df[col], col].to_numpy()\n",
        "        mae = mean_absolute_error(true_vals, imp_vals)\n",
        "        rmse = np.sqrt(mean_squared_error(true_vals, imp_vals))\n",
        "        rows.append({\"feature\": col, \"MAE\": mae, \"RMSE\": rmse})\n",
        "    return pd.DataFrame(rows).set_index(\"feature\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aHGnSlqyUb0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Frequentist baseline: Mean imputation\n"
      ],
      "metadata": {
        "id": "0LklSHvMkifG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_impute(X_train_miss, X_test_miss):\n",
        "    imp = SimpleImputer(strategy=\"mean\")\n",
        "    Xtr = pd.DataFrame(imp.fit_transform(X_train_miss), columns=X_train_miss.columns, index=X_train_miss.index)\n",
        "    Xte = pd.DataFrame(imp.transform(X_test_miss), columns=X_test_miss.columns, index=X_test_miss.index)\n",
        "    return Xtr, Xte\n",
        "\n",
        "mean_results = []\n",
        "mean_errors = {}\n",
        "\n",
        "for r in missing_rates:\n",
        "    pack = data_by_rate[r]\n",
        "    Xtr_imp, Xte_imp = mean_impute(pack[\"X_train_miss\"], pack[\"X_test_miss\"])\n",
        "\n",
        "    met = evaluate_logreg(Xtr_imp, pack[\"y_train\"], Xte_imp, pack[\"y_test\"])\n",
        "    mean_results.append({\"MissingRate\": int(r * 100), **met})\n",
        "\n",
        "    err_te = imputation_error(pack[\"X_test_true\"], Xte_imp, pack[\"mask_test\"])\n",
        "    mean_errors[r] = {\"test\": err_te}\n",
        "\n",
        "mean_results_df = pd.DataFrame(mean_results).set_index(\"MissingRate\").sort_index()\n",
        "display(mean_results_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "MiljXsDiUfLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) MICE (Iterative imputation)\n"
      ],
      "metadata": {
        "id": "WxuY12a8knp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mice_results = []\n",
        "mice_impute_errors = {}\n",
        "\n",
        "for r in missing_rates:\n",
        "    pack = data_by_rate[r]\n",
        "\n",
        "    imp = IterativeImputer(\n",
        "        random_state=42,\n",
        "        sample_posterior=True,\n",
        "        max_iter=15,\n",
        "        initial_strategy=\"mean\"\n",
        "    )\n",
        "\n",
        "    Xtr_imp = pd.DataFrame(\n",
        "        imp.fit_transform(pack[\"X_train_miss\"]),\n",
        "        columns=pack[\"X_train_miss\"].columns,\n",
        "        index=pack[\"X_train_miss\"].index\n",
        "    )\n",
        "    Xte_imp = pd.DataFrame(\n",
        "        imp.transform(pack[\"X_test_miss\"]),\n",
        "        columns=pack[\"X_test_miss\"].columns,\n",
        "        index=pack[\"X_test_miss\"].index\n",
        "    )\n",
        "\n",
        "    met = evaluate_logreg(Xtr_imp, pack[\"y_train\"], Xte_imp, pack[\"y_test\"])\n",
        "    mice_results.append({\"MissingRate\": int(r * 100), **met})\n",
        "\n",
        "    err_te = imputation_error(pack[\"X_test_true\"], Xte_imp, pack[\"mask_test\"])\n",
        "    mice_impute_errors[r] = {\"test\": err_te}\n",
        "\n",
        "mice_results_df = pd.DataFrame(mice_results).set_index(\"MissingRate\").sort_index()\n",
        "display(mice_results_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "WaJn_QgXUjMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xeOEG-fGksOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Metropolis–Hastings imputation (from scratch)\n",
        "\n",
        "We use conditional Gaussian regression models:\n",
        "\\[\n",
        "x_j \\mid x_{-j} \\sim \\mathcal{N}(\\beta_0 + \\beta^T x_{-j}, \\sigma^2)\n",
        "\\]\n",
        "Missing entries are sampled via random-walk MH, then replaced by the post-burn-in mean.\n"
      ],
      "metadata": {
        "id": "430tCWlTksPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_conditional_models(X_miss: pd.DataFrame):\n",
        "    models = {}\n",
        "    cols = list(X_miss.columns)\n",
        "\n",
        "    for col in cols:\n",
        "        other_cols = [c for c in cols if c != col]\n",
        "\n",
        "        ok = X_miss[col].notna()\n",
        "        for oc in other_cols:\n",
        "            ok &= X_miss[oc].notna()\n",
        "\n",
        "        X_other = X_miss.loc[ok, other_cols].to_numpy()\n",
        "        y = X_miss.loc[ok, col].to_numpy()\n",
        "\n",
        "        if len(y) < 20:\n",
        "            mu = float(X_miss[col].mean())\n",
        "            beta = np.array([mu] + [0.0] * len(other_cols))\n",
        "            sigma = float(X_miss[col].std() + 1e-6)\n",
        "            models[col] = (beta, sigma, other_cols)\n",
        "            continue\n",
        "\n",
        "        X_design = np.c_[np.ones(len(X_other)), X_other]\n",
        "        lam = 1e-6\n",
        "        XtX = X_design.T @ X_design + lam * np.eye(X_design.shape[1])\n",
        "        Xty = X_design.T @ y\n",
        "        beta = np.linalg.solve(XtX, Xty)\n",
        "\n",
        "        resid = y - X_design @ beta\n",
        "        sigma = float(np.sqrt(np.mean(resid**2) + 1e-8))\n",
        "\n",
        "        models[col] = (beta, sigma, other_cols)\n",
        "\n",
        "    return models\n",
        "\n",
        "def log_norm_pdf(x, mu, sigma):\n",
        "    return -0.5 * np.log(2 * np.pi * sigma**2) - 0.5 * ((x - mu) ** 2) / (sigma**2)\n",
        "\n",
        "def mh_sample_scalar(mu, sigma, x0, n_steps=250, burn=120, proposal_sd=0.8, rng=None):\n",
        "    if rng is None:\n",
        "        rng = np.random.default_rng()\n",
        "\n",
        "    x = x0\n",
        "    kept = []\n",
        "    accepts = 0\n",
        "\n",
        "    for t in range(n_steps):\n",
        "        x_prop = x + rng.normal(0.0, proposal_sd)\n",
        "\n",
        "        logp_curr = log_norm_pdf(x, mu, sigma)\n",
        "        logp_prop = log_norm_pdf(x_prop, mu, sigma)\n",
        "\n",
        "        if np.log(rng.uniform()) < (logp_prop - logp_curr):\n",
        "            x = x_prop\n",
        "            accepts += 1\n",
        "\n",
        "        if t >= burn:\n",
        "            kept.append(x)\n",
        "\n",
        "    return float(np.mean(kept)), accepts / n_steps\n",
        "\n",
        "def mh_impute_dataset(X_miss: pd.DataFrame, models, n_steps=250, burn=120, proposal_scale=0.8, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    X_imp = X_miss.copy()\n",
        "\n",
        "    for col in X_imp.columns:\n",
        "        X_imp[col] = X_imp[col].fillna(X_imp[col].mean())\n",
        "\n",
        "    acc = {col: [] for col in X_imp.columns}\n",
        "\n",
        "    for col, (beta, sigma, other_cols) in models.items():\n",
        "        miss_idx = X_miss[col].isna()\n",
        "        if not miss_idx.any():\n",
        "            continue\n",
        "\n",
        "        proposal_sd = proposal_scale * sigma\n",
        "\n",
        "        for i in X_miss.index[miss_idx]:\n",
        "            x_other = X_imp.loc[i, other_cols].to_numpy()\n",
        "            mu = float(np.r_[1.0, x_other] @ beta)\n",
        "\n",
        "            x0 = float(X_imp.loc[i, col])\n",
        "            x_mean, a = mh_sample_scalar(mu, sigma, x0, n_steps=n_steps, burn=burn, proposal_sd=proposal_sd, rng=rng)\n",
        "            X_imp.loc[i, col] = x_mean\n",
        "            acc[col].append(a)\n",
        "\n",
        "    acc_summary = {col: (np.mean(v) if len(v) else np.nan) for col, v in acc.items()}\n",
        "    return X_imp, acc_summary\n"
      ],
      "metadata": {
        "id": "1lMVp4t6UoWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mh_results = []\n",
        "mh_errors = {}\n",
        "mh_acc = {}\n",
        "\n",
        "for r in missing_rates:\n",
        "    pack = data_by_rate[r]\n",
        "    models = fit_conditional_models(pack[\"X_train_miss\"])\n",
        "\n",
        "    Xtr_imp, acc_tr = mh_impute_dataset(pack[\"X_train_miss\"], models, n_steps=250, burn=120, proposal_scale=0.8, seed=42)\n",
        "    Xte_imp, acc_te = mh_impute_dataset(pack[\"X_test_miss\"],  models, n_steps=250, burn=120, proposal_scale=0.8, seed=99)\n",
        "\n",
        "    met = evaluate_logreg(Xtr_imp, pack[\"y_train\"], Xte_imp, pack[\"y_test\"])\n",
        "    mh_results.append({\"MissingRate\": int(r * 100), **met})\n",
        "\n",
        "    err_te = imputation_error(pack[\"X_test_true\"], Xte_imp, pack[\"mask_test\"])\n",
        "    mh_errors[r] = {\"test\": err_te}\n",
        "    mh_acc[r] = {\"train\": acc_tr, \"test\": acc_te}\n",
        "\n",
        "mh_results_df = pd.DataFrame(mh_results).set_index(\"MissingRate\").sort_index()\n",
        "display(mh_results_df)\n",
        "\n",
        "print(\"MH acceptance rates (mean per feature):\")\n",
        "for r in missing_rates:\n",
        "    print(f\"\\nMissing {int(r*100)}%\")\n",
        "    display(pd.DataFrame({\"train_accept\": mh_acc[r][\"train\"], \"test_accept\": mh_acc[r][\"test\"]}))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l4Wbg67RUpnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Gibbs sampling imputation (from scratch)\n",
        "\n",
        "We use a Bayesian linear-Gaussian conditional model with weak priors and Gibbs updates:\n",
        "- sample regression parameters given current completed data\n",
        "- sample missing entries given parameters\n",
        "We return the post-burn-in mean for missing entries.\n"
      ],
      "metadata": {
        "id": "b0bSxG1Ok1os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invgamma_sample(a, b, rng):\n",
        "    return 1.0 / rng.gamma(shape=a, scale=1.0 / b)\n",
        "\n",
        "def gibbs_impute_dataset(\n",
        "    X_miss: pd.DataFrame,\n",
        "    n_iter=250,\n",
        "    burn=120,\n",
        "    tau2=10.0,\n",
        "    a0=2.0,\n",
        "    b0=2.0,\n",
        "    seed=42\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    X = X_miss.copy()\n",
        "\n",
        "    for col in X.columns:\n",
        "        X[col] = X[col].fillna(X[col].mean())\n",
        "\n",
        "    cols = list(X.columns)\n",
        "    missing_mask = {col: X_miss[col].isna().to_numpy() for col in cols}\n",
        "\n",
        "    sums = {col: np.zeros(len(X), dtype=float) for col in cols}\n",
        "    kept = 0\n",
        "\n",
        "    for it in range(n_iter):\n",
        "        for col in cols:\n",
        "            other_cols = [c for c in cols if c != col]\n",
        "\n",
        "            y = X[col].to_numpy()\n",
        "            X_other = X[other_cols].to_numpy()\n",
        "            X_design = np.c_[np.ones(len(X_other)), X_other]\n",
        "\n",
        "            p = X_design.shape[1]\n",
        "            XtX = X_design.T @ X_design\n",
        "            Xty = X_design.T @ y\n",
        "\n",
        "            V_inv = XtX + (1.0 / tau2) * np.eye(p)\n",
        "            V = np.linalg.inv(V_inv)\n",
        "            m = V @ Xty\n",
        "\n",
        "            resid = y - X_design @ m\n",
        "            a_n = a0 + len(y) / 2.0\n",
        "            b_n = b0 + 0.5 * (resid @ resid)\n",
        "\n",
        "            sigma2 = invgamma_sample(a_n, b_n, rng)\n",
        "            beta = rng.multivariate_normal(m, sigma2 * V)\n",
        "\n",
        "            miss = missing_mask[col]\n",
        "            if np.any(miss):\n",
        "                mu_all = X_design @ beta\n",
        "                y_new = y.copy()\n",
        "                y_new[miss] = rng.normal(loc=mu_all[miss], scale=np.sqrt(sigma2), size=miss.sum())\n",
        "                X[col] = y_new\n",
        "\n",
        "        if it >= burn:\n",
        "            kept += 1\n",
        "            for col in cols:\n",
        "                miss = missing_mask[col]\n",
        "                if np.any(miss):\n",
        "                    sums[col][miss] += X[col].to_numpy()[miss]\n",
        "\n",
        "    X_out = X.copy()\n",
        "    for col in cols:\n",
        "        miss = missing_mask[col]\n",
        "        if np.any(miss) and kept > 0:\n",
        "            vals = X_out[col].to_numpy()\n",
        "            vals[miss] = sums[col][miss] / kept\n",
        "            X_out[col] = vals\n",
        "\n",
        "    return X_out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dXrM_2luVBZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gibbs_results = []\n",
        "gibbs_errors = {}\n",
        "\n",
        "for r in missing_rates:\n",
        "    pack = data_by_rate[r]\n",
        "\n",
        "    Xtr_imp = gibbs_impute_dataset(pack[\"X_train_miss\"], n_iter=250, burn=120, tau2=10.0, seed=42)\n",
        "    Xte_imp = gibbs_impute_dataset(pack[\"X_test_miss\"],  n_iter=250, burn=120, tau2=10.0, seed=99)\n",
        "\n",
        "    met = evaluate_logreg(Xtr_imp, pack[\"y_train\"], Xte_imp, pack[\"y_test\"])\n",
        "    gibbs_results.append({\"MissingRate\": int(r * 100), **met})\n",
        "\n",
        "    err_te = imputation_error(pack[\"X_test_true\"], Xte_imp, pack[\"mask_test\"])\n",
        "    gibbs_errors[r] = {\"test\": err_te}\n",
        "\n",
        "gibbs_results_df = pd.DataFrame(gibbs_results).set_index(\"MissingRate\").sort_index()\n",
        "display(gibbs_results_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RS1HO0l8VFvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qUwQUtCwlB5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) Clean report tables and plots (all missingness levels)\n",
        "\n",
        "We summarize:\n",
        "- AUC / LogLoss / F1 vs missingness\n",
        "- Average RMSE / MAE vs missingness (test masked entries)\n",
        "- Compact final summary table (AUC + AvgRMSE)\n"
      ],
      "metadata": {
        "id": "4niZfjsclB6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_perf(df_perf, method_name):\n",
        "    out = df_perf.copy()\n",
        "    out[\"Method\"] = method_name\n",
        "    out = out.reset_index()\n",
        "    out = out.rename(columns={out.columns[0]: \"MissingRate\"})\n",
        "    return out[[\"Method\", \"MissingRate\", \"Accuracy\", \"AUC\", \"F1\", \"LogLoss\"]]\n",
        "\n",
        "perf = pd.concat([\n",
        "    prep_perf(mean_results_df, \"Mean\"),\n",
        "    prep_perf(mice_results_df, \"MICE\"),\n",
        "    prep_perf(mh_results_df, \"Metropolis-Hastings\"),\n",
        "    prep_perf(gibbs_results_df, \"Gibbs\")\n",
        "], ignore_index=True).sort_values([\"MissingRate\", \"Method\"]).reset_index(drop=True)\n",
        "\n",
        "display(perf)\n",
        "\n",
        "auc_pivot = perf.pivot(index=\"MissingRate\", columns=\"Method\", values=\"AUC\").sort_index()\n",
        "ll_pivot  = perf.pivot(index=\"MissingRate\", columns=\"Method\", values=\"LogLoss\").sort_index()\n",
        "f1_pivot  = perf.pivot(index=\"MissingRate\", columns=\"Method\", values=\"F1\").sort_index()\n",
        "\n",
        "print(\"AUC\")\n",
        "display(auc_pivot)\n",
        "\n",
        "print(\"LogLoss\")\n",
        "display(ll_pivot)\n",
        "\n",
        "print(\"F1\")\n",
        "display(f1_pivot)\n"
      ],
      "metadata": {
        "id": "MGWDN9jnlDW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_error(err_dict, rates, metric=\"RMSE\"):\n",
        "    rows = []\n",
        "    for r in rates:\n",
        "        rows.append({\"MissingRate\": int(r*100), metric: float(err_dict[r][\"test\"][metric].mean())})\n",
        "    return pd.DataFrame(rows).set_index(\"MissingRate\").sort_index()\n",
        "\n",
        "avg_rmse = pd.concat([\n",
        "    avg_error(mean_errors, missing_rates, \"RMSE\").rename(columns={\"RMSE\":\"Mean\"}),\n",
        "    avg_error(mice_impute_errors, missing_rates, \"RMSE\").rename(columns={\"RMSE\":\"MICE\"}),\n",
        "    avg_error(mh_errors, missing_rates, \"RMSE\").rename(columns={\"RMSE\":\"Metropolis-Hastings\"}),\n",
        "    avg_error(gibbs_errors, missing_rates, \"RMSE\").rename(columns={\"RMSE\":\"Gibbs\"})\n",
        "], axis=1)\n",
        "\n",
        "avg_mae = pd.concat([\n",
        "    avg_error(mean_errors, missing_rates, \"MAE\").rename(columns={\"MAE\":\"Mean\"}),\n",
        "    avg_error(mice_impute_errors, missing_rates, \"MAE\").rename(columns={\"MAE\":\"MICE\"}),\n",
        "    avg_error(mh_errors, missing_rates, \"MAE\").rename(columns={\"MAE\":\"Metropolis-Hastings\"}),\n",
        "    avg_error(gibbs_errors, missing_rates, \"MAE\").rename(columns={\"MAE\":\"Gibbs\"})\n",
        "], axis=1)\n",
        "\n",
        "print(\"Average RMSE (test masked entries)\")\n",
        "display(avg_rmse)\n",
        "\n",
        "print(\"Average MAE (test masked entries)\")\n",
        "display(avg_mae)\n"
      ],
      "metadata": {
        "id": "AM-NqSGblGLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def line_plot(pivot_df, title, ylab):\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    for col in pivot_df.columns:\n",
        "        plt.plot(pivot_df.index, pivot_df[col], marker=\"o\", label=col)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Missingness (%)\")\n",
        "    plt.ylabel(ylab)\n",
        "    plt.xticks(pivot_df.index)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "line_plot(auc_pivot, \"AUC vs Missingness\", \"AUC\")\n",
        "line_plot(ll_pivot,  \"LogLoss vs Missingness\", \"LogLoss\")\n",
        "line_plot(f1_pivot,  \"F1 vs Missingness\", \"F1\")\n",
        "line_plot(avg_rmse,  \"Average RMSE vs Missingness (test masked entries)\", \"Average RMSE\")\n"
      ],
      "metadata": {
        "id": "R9xJ13DQlJny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary = pd.concat([\n",
        "    auc_pivot.add_prefix(\"AUC_\"),\n",
        "    avg_rmse.add_prefix(\"AvgRMSE_\")\n",
        "], axis=1)\n",
        "\n",
        "display(final_summary)\n"
      ],
      "metadata": {
        "id": "biPWGTMSlMJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10) Sensitivity analysis (repeat over seeds)\n",
        "\n",
        "We repeat the full workflow over a small set of random seeds and report mean ± std of:\n",
        "- AUC\n",
        "- Avg RMSE (test masked entries)\n"
      ],
      "metadata": {
        "id": "0IAZV-7qlNfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEEDS = [11, 22, 33, 44, 55]  # increase if time allows\n",
        "\n",
        "sens_rows = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    X_s2, y_s2 = stratified_sample(df, y_full, continuous_cols, N=1000, seed=seed)\n",
        "\n",
        "    X_tr2, X_te2, y_tr2, y_te2 = train_test_split(\n",
        "        X_s2, y_s2, test_size=0.25, random_state=seed, stratify=y_s2\n",
        "    )\n",
        "\n",
        "    for r in missing_rates:\n",
        "        seed_r = int(r * 10_000) + seed\n",
        "        mask_tr = make_mcar_mask(X_tr2, r, seed=seed_r)\n",
        "        mask_te = make_mcar_mask(X_te2, r, seed=seed_r + 1)\n",
        "\n",
        "        Xtr_m = apply_mask(X_tr2, mask_tr)\n",
        "        Xte_m = apply_mask(X_te2, mask_te)\n",
        "\n",
        "        # Mean\n",
        "        Xtr_mean, Xte_mean = mean_impute(Xtr_m, Xte_m)\n",
        "        auc_mean = evaluate_logreg(Xtr_mean, y_tr2, Xte_mean, y_te2)[\"AUC\"]\n",
        "        rmse_mean = float(imputation_error(X_te2, Xte_mean, mask_te)[\"RMSE\"].mean())\n",
        "\n",
        "        # MICE\n",
        "        imp = IterativeImputer(random_state=seed, sample_posterior=True, max_iter=15, initial_strategy=\"mean\")\n",
        "        Xtr_mice = pd.DataFrame(imp.fit_transform(Xtr_m), columns=Xtr_m.columns, index=Xtr_m.index)\n",
        "        Xte_mice = pd.DataFrame(imp.transform(Xte_m), columns=Xte_m.columns, index=Xte_m.index)\n",
        "        auc_mice = evaluate_logreg(Xtr_mice, y_tr2, Xte_mice, y_te2)[\"AUC\"]\n",
        "        rmse_mice = float(imputation_error(X_te2, Xte_mice, mask_te)[\"RMSE\"].mean())\n",
        "\n",
        "        # MH\n",
        "        models = fit_conditional_models(Xtr_m)\n",
        "        Xtr_mh, _ = mh_impute_dataset(Xtr_m, models, n_steps=220, burn=90, proposal_scale=0.8, seed=seed)\n",
        "        Xte_mh, _ = mh_impute_dataset(Xte_m, models, n_steps=220, burn=90, proposal_scale=0.8, seed=seed+100)\n",
        "        auc_mh = evaluate_logreg(Xtr_mh, y_tr2, Xte_mh, y_te2)[\"AUC\"]\n",
        "        rmse_mh = float(imputation_error(X_te2, Xte_mh, mask_te)[\"RMSE\"].mean())\n",
        "\n",
        "        # Gibbs\n",
        "        Xtr_g = gibbs_impute_dataset(Xtr_m, n_iter=220, burn=90, tau2=10.0, seed=seed)\n",
        "        Xte_g = gibbs_impute_dataset(Xte_m, n_iter=220, burn=90, tau2=10.0, seed=seed+200)\n",
        "        auc_g = evaluate_logreg(Xtr_g, y_tr2, Xte_g, y_te2)[\"AUC\"]\n",
        "        rmse_g = float(imputation_error(X_te2, Xte_g, mask_te)[\"RMSE\"].mean())\n",
        "\n",
        "        sens_rows += [\n",
        "            {\"Seed\": seed, \"MissingRate\": int(r*100), \"Method\": \"Mean\", \"AUC\": auc_mean, \"AvgRMSE\": rmse_mean},\n",
        "            {\"Seed\": seed, \"MissingRate\": int(r*100), \"Method\": \"MICE\", \"AUC\": auc_mice, \"AvgRMSE\": rmse_mice},\n",
        "            {\"Seed\": seed, \"MissingRate\": int(r*100), \"Method\": \"Metropolis-Hastings\", \"AUC\": auc_mh, \"AvgRMSE\": rmse_mh},\n",
        "            {\"Seed\": seed, \"MissingRate\": int(r*100), \"Method\": \"Gibbs\", \"AUC\": auc_g, \"AvgRMSE\": rmse_g},\n",
        "        ]\n",
        "\n",
        "sens_df = pd.DataFrame(sens_rows)\n",
        "\n",
        "sens_summary = (\n",
        "    sens_df.groupby([\"MissingRate\", \"Method\"])\n",
        "    .agg(\n",
        "        AUC_mean=(\"AUC\", \"mean\"),\n",
        "        AUC_std=(\"AUC\", \"std\"),\n",
        "        RMSE_mean=(\"AvgRMSE\", \"mean\"),\n",
        "        RMSE_std=(\"AvgRMSE\", \"std\")\n",
        "    )\n",
        "    .reset_index()\n",
        "    .sort_values([\"MissingRate\", \"Method\"])\n",
        ")\n",
        "\n",
        "display(sens_summary)\n"
      ],
      "metadata": {
        "id": "0VgiUl9wlPcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mean_std(summary_df, mean_col, std_col, title, ylab):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    for method in summary_df[\"Method\"].unique():\n",
        "        sub = summary_df[summary_df[\"Method\"] == method].sort_values(\"MissingRate\")\n",
        "        x = sub[\"MissingRate\"].to_numpy()\n",
        "        y = sub[mean_col].to_numpy()\n",
        "        yerr = sub[std_col].to_numpy()\n",
        "        plt.errorbar(x, y, yerr=yerr, marker=\"o\", capsize=4, label=method)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Missingness (%)\")\n",
        "    plt.ylabel(ylab)\n",
        "    plt.xticks(sorted(summary_df[\"MissingRate\"].unique()))\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_mean_std(sens_summary, \"AUC_mean\", \"AUC_std\", \"Sensitivity: AUC (mean ± std)\", \"AUC\")\n",
        "plot_mean_std(sens_summary, \"RMSE_mean\", \"RMSE_std\", \"Sensitivity: Avg RMSE (mean ± std)\", \"Average RMSE\")\n"
      ],
      "metadata": {
        "id": "RvxMez6IlTeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11) Lightweight convergence checks (MCMC)\n",
        "\n",
        "We show:\n",
        "- MH trace + running mean for one missing entry (10% case)\n",
        "- Gibbs trace + running mean for the same conditional (10% case)\n",
        "This supports basic convergence/mixing discussion.\n"
      ],
      "metadata": {
        "id": "HYxqa4EQlU7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def running_mean(x):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    return np.cumsum(x) / (np.arange(len(x)) + 1)\n",
        "\n",
        "r = 0.10\n",
        "pack = data_by_rate[r]\n",
        "Xtr_m = pack[\"X_train_miss\"].copy()\n",
        "mask_tr = pack[\"mask_train\"]\n",
        "\n",
        "col = \"age\"\n",
        "miss_idx = Xtr_m.index[mask_tr[col]]\n",
        "if len(miss_idx) == 0:\n",
        "    raise ValueError(\"No missing entries found to monitor. Try another column.\")\n",
        "\n",
        "i0 = miss_idx[0]\n",
        "print(\"Monitoring:\", col, \"row:\", i0)\n",
        "\n",
        "models = fit_conditional_models(Xtr_m)\n",
        "beta, sigma, other_cols = models[col]\n",
        "\n",
        "X_init = Xtr_m.copy()\n",
        "for c in X_init.columns:\n",
        "    X_init[c] = X_init[c].fillna(X_init[c].mean())\n",
        "\n",
        "x_other = X_init.loc[i0, other_cols].to_numpy()\n",
        "mu = float(np.r_[1.0, x_other] @ beta)\n",
        "\n",
        "rng = np.random.default_rng(123)\n",
        "x = float(X_init.loc[i0, col])\n",
        "proposal_sd = 0.8 * sigma\n",
        "\n",
        "mh_chain = []\n",
        "accepts = 0\n",
        "n_steps = 600\n",
        "burn = 200\n",
        "\n",
        "for t in range(n_steps):\n",
        "    x_prop = x + rng.normal(0.0, proposal_sd)\n",
        "    if np.log(rng.uniform()) < (log_norm_pdf(x_prop, mu, sigma) - log_norm_pdf(x, mu, sigma)):\n",
        "        x = x_prop\n",
        "        accepts += 1\n",
        "    mh_chain.append(x)\n",
        "\n",
        "plt.figure(figsize=(7,3))\n",
        "plt.plot(mh_chain, alpha=0.8)\n",
        "plt.axvline(burn, linestyle=\"--\")\n",
        "plt.plot(running_mean(mh_chain), linewidth=2)\n",
        "plt.title(f\"MH trace + running mean (accept rate ~ {accepts/n_steps:.2f})\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(col)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "rng = np.random.default_rng(456)\n",
        "gibbs_chain = []\n",
        "sigma2 = sigma**2\n",
        "x = float(X_init.loc[i0, col])\n",
        "\n",
        "for t in range(n_steps):\n",
        "    x = rng.normal(loc=mu, scale=np.sqrt(sigma2))\n",
        "    gibbs_chain.append(x)\n",
        "\n",
        "plt.figure(figsize=(7,3))\n",
        "plt.plot(gibbs_chain, alpha=0.8)\n",
        "plt.axvline(burn, linestyle=\"--\")\n",
        "plt.plot(running_mean(gibbs_chain), linewidth=2)\n",
        "plt.title(\"Gibbs trace + running mean (single-entry conditional)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(col)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1iR5cPc5lXde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_teiXgclZ_u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}